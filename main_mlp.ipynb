{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Utility Function"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "\n",
                "\n",
                "def linear(x):\n",
                "    return x\n",
                "\n",
                "\n",
                "def relu(x):\n",
                "    return np.maximum(x, 0)\n",
                "\n",
                "\n",
                "def sigmoid(x):\n",
                "    return 1.0 / (1.0 + np.exp(-x))\n",
                "\n",
                "\n",
                "def softmax(x):\n",
                "    e_x = np.exp(x - np.max(x))\n",
                "    return e_x / e_x.sum(axis=0)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## MLPClassifier Implementation"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Parameter yang ada pada kelas MLPClassifier yaitu: **struktur jaringan (jumlah layer, jumlah neuron setiap layer, fungsi aktivasi setiap layer), initial weights tiap neuron, learning_rate, error_threshold, max_iter, batch_size**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [],
            "source": [
                "import math\n",
                "import numpy as np\n",
                "import os\n",
                "import json\n",
                "from utils import sigmoid, relu, softmax, linear\n",
                "\n",
                "\n",
                "class FFNNLayer:\n",
                "    def __init__(self, number_of_neurons: int, activation_function: str):\n",
                "        \"\"\"\n",
                "        :param number_of_neurons:\n",
                "        :param activation_function:\n",
                "        \"\"\"\n",
                "        self.number_of_neurons = number_of_neurons\n",
                "        self.activation_function = activation_function\n",
                "\n",
                "\n",
                "class MLPClassifier:\n",
                "    def __init__(self, layers: list, weights, learning_rate=None, error_threshold=None, max_iter=None, batch_size=None,  stopped_by=None, expected_weights = None):\n",
                "        \"\"\"\n",
                "        :param layers: list of FFNNLayer to specify the activation function and num of neurons for each layers\n",
                "        :param learning_rate: the learning rate\n",
                "        :param error_threshold: the error threshold\n",
                "        :param max_iter: max iter to stop iteration\n",
                "        :param batch_size: the size of batch for each mini batch\n",
                "        \"\"\"\n",
                "        self.num_of_layers = len(layers)\n",
                "        self.layers = layers\n",
                "        self.learning_rate = learning_rate\n",
                "        self.error_threshold = error_threshold\n",
                "        self.error_sum = 1\n",
                "        self.max_iter = max_iter\n",
                "        self.batch_size = batch_size\n",
                "        self.X_train = []\n",
                "        self.y_train = []\n",
                "        self.neuron_values = []\n",
                "        self.weights = [weight[1:] for weight in weights]\n",
                "        self.bias_weights = [weight[0] for weight in weights]\n",
                "        self.prediction = []\n",
                "        self.num_of_features = 0\n",
                "        self.num_of_batches = 0\n",
                "        self.d_weights = None\n",
                "        self.d_bias_weights = None\n",
                "        self.expected_stopped_by = stopped_by\n",
                "        self.expected_weights = expected_weights\n",
                "        self.expected_output = None\n",
                "        self.stopped_by = None\n",
                "        self.current_inputs = None\n",
                "\n",
                "    def fit(self, X_train, y_train):\n",
                "        self.X_train = X_train\n",
                "        self.y_train = y_train\n",
                "        self.num_of_features = len(self.X_train)\n",
                "        self.num_of_batches = math.ceil(len(self.X_train) / self.batch_size)\n",
                "\n",
                "        # the first neuron is the X inputs themselves\n",
                "        self.neuron_values = [[None for _ in range(layer.number_of_neurons)] for layer in self.layers]\n",
                "        num_iter = 0\n",
                "        while num_iter < self.max_iter:\n",
                "            num_of_batches = math.ceil(len(self.X_train) / self.batch_size)\n",
                "            err = 0\n",
                "            for i in range(num_of_batches):\n",
                "                self.__forward(i)\n",
                "                self.__backward(i)\n",
                "                err += self.__calculate_error(i)\n",
                "\n",
                "            # Update the average error for this iteration\n",
                "            self.error_sum = err / num_of_batches\n",
                "\n",
                "            # Check if the error is below the threshold\n",
                "            if self.error_sum <= self.error_threshold:\n",
                "                break\n",
                "\n",
                "            num_iter += 1\n",
                "\n",
                "        self.stopped_by = \"max_iteration\" if num_iter == self.max_iter else \"error_threshold\"\n",
                "\n",
                "        if self.expected_weights:\n",
                "            self.__print_final_weights()\n",
                "\n",
                "    def predict(self, X_test):\n",
                "        \"\"\"Perform forward pass to make predictions on input X_test\n",
                "\n",
                "        Args:\n",
                "            X_test: Input data for prediction (list)\n",
                "\n",
                "        Returns:\n",
                "            Predicted outputs for each sample in X_test\n",
                "        \"\"\"\n",
                "        current_inputs = np.array(X_test)\n",
                "        for i in range(self.num_of_layers):\n",
                "            net = [np.matmul(x, self.weights[i]) + self.bias_weights[i] for x in current_inputs]\n",
                "            act_func = self.layers[i].activation_function\n",
                "            if act_func == 'linear':\n",
                "                res = [linear(x) for x in net]\n",
                "            elif act_func == 'relu':\n",
                "                res = [relu(n) for n in net]\n",
                "            elif act_func == 'sigmoid':\n",
                "                res = [sigmoid(n) for n in net]\n",
                "            elif act_func == \"softmax\":\n",
                "                res = [softmax(n) for n in net]\n",
                "            current_inputs = res\n",
                "        return res\n",
                "\n",
                "    def calculate_sse(self):\n",
                "        sse = 0\n",
                "        for layer in range(len(self.expected_weights)):\n",
                "            for neuron in range(len(self.expected_weights[layer])):\n",
                "                expected = np.array(self.expected_weights[layer][neuron])\n",
                "                result = self.bias_weights[layer] if neuron == 0 else self.weights[layer][neuron-1]\n",
                "                squared_error = (expected - result) ** 2\n",
                "                sse += np.sum(squared_error)\n",
                "        return sse\n",
                "\n",
                "    def __forward(self, batch):\n",
                "        start_idx = self.batch_size * batch\n",
                "        self.expected_output = self.y_train[start_idx:start_idx + self.__get_curr_batch_size(batch)]\n",
                "        self.current_inputs = self.X_train[start_idx:start_idx + self.__get_curr_batch_size(batch)]\n",
                "        res = self.current_inputs\n",
                "        for i in range(self.num_of_layers):\n",
                "            net = [np.matmul(x, self.weights[i]) + self.bias_weights[i] for x in res]\n",
                "            act_func = self.layers[i].activation_function\n",
                "            if act_func == 'linear':\n",
                "                res = [linear(x) for x in net]\n",
                "            if act_func == 'relu':\n",
                "                res = [relu(n) for n in net]\n",
                "            if act_func == 'sigmoid':\n",
                "                res = [sigmoid(n) for n in net]\n",
                "            if act_func == \"softmax\":\n",
                "                res = [softmax(n) for n in net]\n",
                "            self.neuron_values[i] = res\n",
                "        # print(\"pred\", self.neuron_values[-1])    \n",
                "        self.prediction = list(self.neuron_values[-1])\n",
                "\n",
                "    def __backward(self, batch_idx):\n",
                "        \"\"\"\n",
                "        do backward propagation for each batch\n",
                "        :param batch_idx: the current batch that is processed\n",
                "        \"\"\"\n",
                "        self.__init_d_weights()\n",
                "        # get the current batch size\n",
                "        batch_size = self.__get_curr_batch_size(batch_idx)\n",
                "\n",
                "        # for each X in the batch\n",
                "        for i in range(batch_size):\n",
                "            d_k = np.zeros(0)\n",
                "            for j in range(self.num_of_layers - 1, -1, -1):\n",
                "                if j == self.num_of_layers - 1:       \n",
                "                    delta = self.__calc_output_layer_delta(i)\n",
                "                else:\n",
                "                    delta = self.__calc_hidden_layer_delta(i, j, d_k)\n",
                "                x = self.current_inputs[i] if j == 0 else self.neuron_values[j - 1][i]\n",
                "                self.d_weights[j] += np.array([[d * n for d in delta] for n in x])\n",
                "                self.d_bias_weights[j] += np.array(delta)\n",
                "                d_k = delta.reshape(delta.shape[0], 1)\n",
                "        \n",
                "        self.weights = [np.array(self.weights[k]) + np.array(self.d_weights[k]) * self.learning_rate for k in\n",
                "                        range(len(self.weights))]\n",
                "        self.bias_weights = [np.array(self.bias_weights[k]) + np.array(self.d_bias_weights[k]) * self.learning_rate for\n",
                "                             k in range(len(self.bias_weights))]\n",
                "\n",
                "    def __calculate_error(self, batch_idx):\n",
                "        \"\"\"\n",
                "        Calculate the error for the current batch\n",
                "        :param batch_idx: the current batch that is processed\n",
                "        \"\"\"\n",
                "        start_idx = self.batch_size * batch_idx\n",
                "        end_idx = start_idx + self.__get_curr_batch_size(batch_idx)\n",
                "        y_true = np.array(self.y_train[start_idx:end_idx])\n",
                "        y_pred = np.array(self.prediction)\n",
                "\n",
                "        # Get the activation function of the output layer\n",
                "        act_func = self.layers[-1].activation_function\n",
                "\n",
                "        # Calculate the error based on the activation function\n",
                "        if act_func in ['relu', 'sigmoid', 'linear']:\n",
                "            return 0.5 * np.sum((y_true - y_pred) ** 2)\n",
                "        elif act_func == 'softmax':\n",
                "            return -np.sum(y_true * np.log(y_pred))\n",
                "        else:\n",
                "            raise ValueError(f\"Unsupported activation function: {act_func}\")\n",
                "\n",
                "    def __update_weights(self):\n",
                "        self.weights = [np.array(self.weights[k]) + np.array(self.d_weights[k]) * self.learning_rate for k in\n",
                "                        range(len(self.weights))]\n",
                "        self.bias_weights = [np.array(self.bias_weights[k]) + np.array(self.d_bias_weights[k]) * self.learning_rate for\n",
                "                             k in range(len(self.bias_weights))]\n",
                "\n",
                "    def __init_d_weights(self):\n",
                "        self.d_weights = [np.array([np.zeros(len(neuron_weight)) for neuron_weight in layer_weight])\n",
                "                          for layer_weight in self.weights]\n",
                "        self.d_bias_weights = [np.zeros(layer.number_of_neurons) for layer in self.layers]\n",
                "\n",
                "    def __calc_output_diff(self, x_idx: int) -> np.ndarray:\n",
                "        \"\"\"\n",
                "        :param x_idx:  the index of the current input on the X_train\n",
                "        \"\"\"\n",
                "        y_train = self.expected_output[x_idx]  # get the expected output of the x\n",
                "        output = self.prediction[x_idx]  # get the prediction\n",
                "        return np.array([y - p for y, p in zip(y_train, output)])\n",
                "\n",
                "    def __calc_act_function_derivative(self, act_func: str, y: list, target=None) -> np.ndarray:\n",
                "        \"\"\"\n",
                "        :param y:  y is the output in a layer\n",
                "\n",
                "        :return : a 1D array which is the sigmoid gradient of the neurons in a layer\n",
                "        \"\"\"\n",
                "        if act_func == 'sigmoid':\n",
                "            return np.array([x * (1-x) for x in y])\n",
                "\n",
                "        elif act_func == 'relu':\n",
                "            return np.array([1 if x > 0 else 0 for x in y])\n",
                "\n",
                "        elif act_func == 'linear':\n",
                "            return np.array([1 for _ in y])\n",
                "\n",
                "        elif act_func == 'softmax':\n",
                "            if target is None:\n",
                "                raise ValueError(\"Target is required for softmax gradient\")\n",
                "            return np.array([-1 * (1-y[i]) if target == i else y[i] for i in range(len(y))])\n",
                "\n",
                "        else:\n",
                "            raise ValueError(f\"Unknown activation function: {act_func}\")\n",
                "\n",
                "\n",
                "    def __calc_output_layer_delta(self, x_idx: int) -> np.ndarray:\n",
                "        \"\"\"\n",
                "        :param x_idx:  the index of the current input on the X_train\n",
                "        \"\"\"\n",
                "        # get the activation function for the last layer (output layer)\n",
                "        act_func = self.layers[-1].activation_function  # get the activation function\n",
                "    \n",
                "        if act_func == 'softmax':\n",
                "            return self.__calc_output_diff(x_idx)\n",
                "        return self.__calc_act_function_derivative(act_func, self.prediction[x_idx]) * self.__calc_output_diff(x_idx)\n",
                "\n",
                "    def __calc_hidden_layer_delta(self, batch_idx, layer_idx: int, output_error_term: np.ndarray) -> np.ndarray:\n",
                "        \"\"\"\n",
                "        :param output_error_term: a 1D array of the error term of each weight calculated from the layer after\n",
                "        :param layer_idx: the index of the current layer\n",
                "        :param batch_idx: the index of the current batch\n",
                "\n",
                "        hidden layer gradient = net gradient of the neuron values of current layer * the sum of weight * output error term\n",
                "        \"\"\"\n",
                "        act_func = self.layers[layer_idx].activation_function\n",
                "        activation_func_derivative = self.__calc_act_function_derivative(act_func,\n",
                "                                                                         self.neuron_values[layer_idx][batch_idx])\n",
                "\n",
                "        sum_d_net = [x[0] for x in np.matmul(self.weights[layer_idx + 1], output_error_term)]\n",
                "        return np.array(activation_func_derivative\n",
                "                        * sum_d_net)\n",
                "\n",
                "    def __get_curr_batch_size(self, batch_idx):\n",
                "        mod_res = len(self.X_train) % self.batch_size\n",
                "        if batch_idx == self.num_of_batches - 1 and mod_res != 0:\n",
                "            return mod_res\n",
                "        return self.batch_size\n",
                "\n",
                "    def __print_final_weights(self):\n",
                "        print(\"========= EXPECTED =========\")\n",
                "        for weight in self.expected_weights:\n",
                "            print(\"[\")\n",
                "            for neuron_weight in weight:\n",
                "                print(\"  \", neuron_weight)\n",
                "            print(\"], \")\n",
                "        print(\"STOPPED BY: \", self.expected_stopped_by)\n",
                "\n",
                "        print(\"========== ACTUAL ==========\")\n",
                "\n",
                "        for i in range(len(self.weights)):\n",
                "            print(\"[\")\n",
                "            print(\"  \", self.bias_weights[i])\n",
                "            for neuron_weight in self.weights[i]:\n",
                "                print(\"  \", neuron_weight)\n",
                "            print(\"], \")\n",
                "        print(\"STOPPED BY: \", self.stopped_by)\n",
                "    \n",
                "    def calc_score(self, y_true, predictions):\n",
                "        \"\"\"\n",
                "        Calculate the accuracy of predictions.\n",
                "\n",
                "        :param y_true: True labels.\n",
                "        :param predictions: Predictions from the model, as probabilities.\n",
                "        \n",
                "        :return: Accuracy as a float.\n",
                "        \"\"\"\n",
                "        y_pred_indices = np.argmax(predictions, axis=1)\n",
                "        y_true_indices = np.argmax(y_true, axis=1)\n",
                "        \n",
                "        accuracy = np.mean(y_pred_indices == y_true_indices)\n",
                "        return accuracy\n",
                "    \n",
                "    def save_model(self, file_name, directory=\"model\"):\n",
                "            \"\"\"\n",
                "            Saves the model weights and configuration to model directory.\n",
                "            \"\"\"\n",
                "            if not os.path.exists(directory):\n",
                "                os.makedirs(directory)\n",
                "            \n",
                "            model_data = {\n",
                "            \"final_weights\": [],\n",
                "            \"config\": {\n",
                "                \"layers\": [{\"number_of_neurons\": layer.number_of_neurons,\n",
                "                            \"activation_function\": layer.activation_function} for layer in self.layers],\n",
                "                }\n",
                "            }\n",
                "\n",
                "            for weights, bias in zip(self.weights, self.bias_weights):\n",
                "                bias_rounded = np.round(bias, 6)\n",
                "                weights_rounded = np.round(weights,6)\n",
                "                bias_reshaped = np.reshape(bias_rounded, (1, len(bias_rounded)))\n",
                "                integrated_layer_weights = np.vstack([bias_reshaped, weights_rounded])\n",
                "                model_data[\"final_weights\"].append(integrated_layer_weights.tolist())\n",
                "\n",
                "            new_file_name = \"model-\" + os.path.basename(file_name)\n",
                "            # Save to JSON file\n",
                "            with open(os.path.join(directory, new_file_name), \"w\") as json_file:\n",
                "                json.dump(model_data, json_file)\n",
                "            \n",
                "            print(\"Model saved successfully to JSON.\")\n",
                "\n",
                "    @classmethod\n",
                "    def load_model(cls, file_name, directory=\"model\"):\n",
                "        \"\"\"\n",
                "        Loads the model weights and configuration from model directory.\n",
                "        \"\"\"\n",
                "        # Load configuration\n",
                "        with open(os.path.join(directory, file_name), \"r\") as json_file:\n",
                "            model_data = json.load(json_file)\n",
                "        \n",
                "        layers = [FFNNLayer\n",
                "                  (layer_conf[\"number_of_neurons\"], layer_conf[\"activation_function\"])\n",
                "                  for layer_conf in model_data[\"config\"][\"layers\"]\n",
                "                ]\n",
                "        \n",
                "        #  Create new instance\n",
                "        classifier = cls(\n",
                "            layers=layers,\n",
                "            weights=[],  \n",
                "        )\n",
                "\n",
                "        classifier.weights = []\n",
                "        classifier.bias_weights = []\n",
                "        for integrated_weights in model_data[\"final_weights\"]:\n",
                "            np_weights = np.array(integrated_weights)\n",
                "            classifier.bias_weights.append(np_weights[0, :])\n",
                "            classifier.weights.append(np_weights[1:, :])  \n",
                "        return classifier\n",
                "    \n",
                "    def printModel(self):\n",
                "        for i in range(len(self.weights)):\n",
                "            print(\"[\")\n",
                "            print(\"  \", self.bias_weights[i])\n",
                "            for neuron_weight in self.weights[i]:\n",
                "                print(\"  \", neuron_weight)\n",
                "            print(\"], \")\n",
                "    "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Main Program"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Dijalankan untuk melakukan pengujian berdasarkan test case yang diberikan. Test case diuji dengan menuliskan path dari file test case pada input."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "========= EXPECTED =========\n",
                        "[\n",
                        "   [0.08592, 0.32276]\n",
                        "   [-0.33872, 0.46172]\n",
                        "   [0.449984, 0.440072]\n",
                        "], \n",
                        "[\n",
                        "   [0.2748, 0.188]\n",
                        "   [0.435904, -0.53168]\n",
                        "   [0.68504, 0.7824]\n",
                        "], \n",
                        "STOPPED BY:  max_iteration\n",
                        "========== ACTUAL ==========\n",
                        "[\n",
                        "   [0.08592 0.32276]\n",
                        "   [-0.33872  0.46172]\n",
                        "   [0.449984 0.440072]\n",
                        "], \n",
                        "[\n",
                        "   [0.2748 0.188 ]\n",
                        "   [ 0.435904 -0.53168 ]\n",
                        "   [0.68504 0.7824 ]\n",
                        "], \n",
                        "STOPPED BY:  max_iteration\n",
                        "Sum Squared Error: 0.0000\n",
                        "Sum Squared Error(SSE) of prediction is lower than Maximum SSE\n",
                        "Model saved successfully to JSON.\n"
                    ]
                }
            ],
            "source": [
                "import json\n",
                "file_path = input(\"Enter json file path: \")\n",
                "f = open(file_path)\n",
                "data = json.load(f)\n",
                "\n",
                "try:\n",
                "    data_layers = data[\"case\"][\"model\"][\"layers\"]\n",
                "    layers = []\n",
                "    for layer in data_layers:\n",
                "        activation_func = layer[\"activation_function\"]\n",
                "        if activation_func not in [\"linear\", \"relu\", \"sigmoid\", \"softmax\"]:\n",
                "            raise Exception(\"Activation function \" + activation_func + \" not available\")\n",
                "        layers.append(FFNNLayer(layer[\"number_of_neurons\"], activation_func))\n",
                "\n",
                "    weights = data[\"case\"][\"initial_weights\"]\n",
                "    input_size = data[\"case\"][\"model\"][\"input_size\"]\n",
                "    X_train = data[\"case\"][\"input\"]\n",
                "    y_train = data[\"case\"][\"target\"]\n",
                "    learning_rate = data[\"case\"][\"learning_parameters\"][\"learning_rate\"]\n",
                "    batch_size = data[\"case\"][\"learning_parameters\"][\"batch_size\"]\n",
                "    max_iteration = data[\"case\"][\"learning_parameters\"][\"max_iteration\"]\n",
                "    error_threshold = data[\"case\"][\"learning_parameters\"][\"error_threshold\"]\n",
                "\n",
                "    expected_weights = data[\"expect\"][\"final_weights\"]\n",
                "    expected_stopped_by = data[\"expect\"][\"stopped_by\"]\n",
                "\n",
                "    model = MLPClassifier(layers, weights, learning_rate, error_threshold, max_iteration, batch_size, expected_stopped_by, expected_weights)\n",
                "\n",
                "    model.fit(X_train, y_train)\n",
                "\n",
                "    sse = model.calculate_sse()\n",
                "    print(f\"Sum Squared Error: {sse:.4f}\")\n",
                "    if sse < 1e-7:\n",
                "        print(\"Sum Squared Error(SSE) of prediction is lower than Maximum SSE\")\n",
                "    else:\n",
                "        print(\"Sum Squared Error(SSE) of prediction surpass the Maximum SSE\")\n",
                "    model.save_model(file_path)\n",
                "except KeyError as ke:\n",
                "    print('Key', ke, \"not found in json data. Please check your json data format\")\n",
                "except Exception as error:\n",
                "    print(\"An exception occurred: \", error)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[\n",
                        "   [0.08592 0.32276]\n",
                        "   [-0.33872  0.46172]\n",
                        "   [0.449984 0.440072]\n",
                        "], \n",
                        "[\n",
                        "   [0.2748 0.188 ]\n",
                        "   [ 0.435904 -0.53168 ]\n",
                        "   [0.68504 0.7824 ]\n",
                        "], \n"
                    ]
                }
            ],
            "source": [
                "model = MLPClassifier.load_model(\"model-mlp.json\")\n",
                "model.printModel()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Pengujian pada Dataset Iris"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Akan dilakukan pengujian pada dataset iris dengan parameter sebagai berikut:\n",
                "* Struktur jaringan: 2 hidden layer dengan masing-masing 3 neuron dan fungsi aktivasi ReLU\n",
                "* Initial weights: akan diinitialize secara random dengan nilai dalam interval -0.5 - 0.5\n",
                "* learning_rate: 0.1\n",
                "* error_threshold: 0.0001\n",
                "* max_iter: 1000\n",
                "* batch_size: 50"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Preprocessing data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[[1, 0, 0], [1, 0, 0], [0, 0, 1], [0, 0, 1], [1, 0, 0], [1, 0, 0], [0, 0, 1], [0, 0, 1], [1, 0, 0], [1, 0, 0], [0, 0, 1], [0, 0, 1], [0, 1, 0], [0, 0, 1], [0, 1, 0], [0, 0, 1], [1, 0, 0], [0, 0, 1], [0, 0, 1], [1, 0, 0], [0, 1, 0], [1, 0, 0], [0, 0, 1], [0, 1, 0], [1, 0, 0], [0, 1, 0], [0, 1, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [0, 1, 0], [0, 1, 0], [0, 0, 1], [1, 0, 0], [0, 1, 0], [0, 0, 1], [0, 0, 1], [0, 0, 1], [1, 0, 0], [0, 1, 0], [1, 0, 0], [0, 0, 1], [0, 1, 0], [0, 1, 0], [0, 1, 0], [1, 0, 0], [0, 0, 1], [0, 0, 1], [0, 1, 0], [0, 1, 0], [0, 0, 1], [0, 1, 0], [0, 1, 0], [0, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [0, 1, 0], [1, 0, 0], [1, 0, 0], [0, 1, 0], [0, 1, 0], [1, 0, 0], [0, 1, 0], [0, 1, 0], [0, 1, 0], [0, 0, 1], [0, 1, 0], [0, 0, 1], [1, 0, 0], [0, 1, 0], [0, 1, 0], [1, 0, 0], [0, 1, 0], [1, 0, 0], [0, 1, 0], [1, 0, 0], [0, 0, 1], [0, 0, 1], [1, 0, 0], [0, 0, 1], [1, 0, 0], [0, 0, 1], [0, 1, 0], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 1, 0], [1, 0, 0], [0, 1, 0], [0, 1, 0], [0, 0, 1], [0, 1, 0], [1, 0, 0], [1, 0, 0], [0, 0, 1], [1, 0, 0], [0, 0, 1], [1, 0, 0], [0, 1, 0], [1, 0, 0], [0, 0, 1], [0, 1, 0], [1, 0, 0], [1, 0, 0], [0, 1, 0], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 0], [0, 0, 1], [1, 0, 0], [0, 0, 1], [1, 0, 0]]\n"
                    ]
                }
            ],
            "source": [
                "import numpy as np\n",
                "import pandas as pd\n",
                "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
                "from sklearn.model_selection import train_test_split\n",
                "\n",
                "# Load the data\n",
                "data = pd.read_csv(\"test_cases_mlp/iris.csv\")\n",
                "\n",
                "# Split the data\n",
                "X = data.drop(columns=[\"Species\"])\n",
                "y = data[\"Species\"]\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n",
                "\n",
                "# Standardize the data\n",
                "scaler = StandardScaler()\n",
                "X_train = scaler.fit_transform(X_train)\n",
                "X_test = scaler.transform(X_test)\n",
                "\n",
                "# Encode the data\n",
                "encoder = LabelEncoder()\n",
                "y_train_encoded = encoder.fit_transform(y_train)\n",
                "y_test_encoded = encoder.transform(y_test)\n",
                "\n",
                "def one_hot_encode(labels, num_classes):\n",
                "    one_hot = np.zeros((len(labels), num_classes), dtype=int)\n",
                "    one_hot[np.arange(len(labels)), labels] = 1\n",
                "    return one_hot.tolist()\n",
                "\n",
                "# One-hot encode the labels\n",
                "y_train = one_hot_encode(y_train_encoded, 3)\n",
                "y_test = one_hot_encode(y_test_encoded, 3)\n",
                "\n",
                "print(y_train)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Pengujian pada kelas implementasi MLPClassifier"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Model saved successfully to JSON.\n",
                        "[array([1.86133812e-09, 4.74620410e-04, 9.99525378e-01]), array([1.55447939e-06, 9.73661583e-01, 2.63368623e-02]), array([0.01020557, 0.98249172, 0.00730272]), array([1.46116336e-09, 2.52126767e-04, 9.99747872e-01]), array([2.55971354e-04, 9.99329090e-01, 4.14938689e-04]), array([9.96701070e-01, 3.29893004e-03, 3.26046003e-15]), array([9.99695061e-01, 3.04938867e-04, 1.36978718e-14]), array([9.99894675e-01, 1.05324989e-04, 1.70228930e-17]), array([1.68105987e-04, 9.88428687e-01, 1.14032071e-02]), array([1.71204122e-09, 6.96659605e-04, 9.99303339e-01]), array([9.96721592e-01, 3.27840778e-03, 6.44846219e-14]), array([9.99245192e-01, 7.54807612e-04, 2.88573767e-14]), array([1.07396698e-11, 1.36018663e-05, 9.99986398e-01]), array([9.98777984e-01, 1.22201641e-03, 4.33477294e-16]), array([8.16550346e-12, 3.21552551e-05, 9.99967845e-01]), array([9.97113667e-01, 2.88633270e-03, 4.22107359e-14]), array([2.65346682e-10, 5.90780170e-05, 9.99940922e-01]), array([9.98413034e-12, 3.80574668e-03, 9.96194253e-01]), array([2.78027709e-04, 9.98691651e-01, 1.03032111e-03]), array([2.67099577e-05, 9.99906404e-01, 6.68864984e-05]), array([9.99007467e-01, 9.92532665e-04, 1.03557065e-14]), array([1.73318490e-09, 7.21558531e-05, 9.99927842e-01]), array([8.89840038e-01, 1.10159962e-01, 6.29113334e-11]), array([7.17274248e-06, 9.03137803e-01, 9.68550240e-02]), array([1.35976346e-07, 7.27175183e-02, 9.27282346e-01]), array([7.39453154e-03, 9.92532336e-01, 7.31328716e-05]), array([3.89987514e-04, 9.99555007e-01, 5.50051004e-05]), array([5.54820842e-05, 9.98484491e-01, 1.46002662e-03]), array([4.10169246e-07, 5.28187647e-02, 9.47180825e-01]), array([9.99906950e-01, 9.30497313e-05, 3.18970491e-18])]\n"
                    ]
                }
            ],
            "source": [
                "import random\n",
                "\n",
                "layers = [\n",
                "    FFNNLayer(3, 'softmax')\n",
                "]\n",
                "initial_weights = [[[random.uniform(-0.5, 0.5) for _ in range(layer.number_of_neurons)] for _ in range (6)] for layer in layers]\n",
                "implementation_model = MLPClassifier(layers=layers,  weights=initial_weights, learning_rate=0.1, error_threshold=0.0001, max_iter=100, batch_size=50, stopped_by=\"error_threshold\")\n",
                "implementation_model.fit(X_train, y_train)\n",
                "implementation_model.save_model(\"iris.json\")\n",
                "print(implementation_model.predict(X_test))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[\n",
                        "   [-0.648318  4.39781  -4.351018]\n",
                        "   [-2.693013 -2.114401  5.124479]\n",
                        "   [-2.040737  0.79923   0.614372]\n",
                        "   [ 2.272703 -0.634508 -1.612536]\n",
                        "   [-3.334569  0.74872   2.743007]\n",
                        "   [-2.541526 -1.363021  3.903661]\n",
                        "], \n",
                        "Prediction: [array([1.86133796e-09, 4.74620792e-04, 9.99525377e-01]), array([1.55448089e-06, 9.73661542e-01, 2.63369031e-02]), array([0.01020557, 0.98249169, 0.00730273]), array([1.46116327e-09, 2.52126736e-04, 9.99747872e-01]), array([2.55971553e-04, 9.99329089e-01, 4.14939016e-04]), array([9.96701074e-01, 3.29892627e-03, 3.26045972e-15]), array([9.99695061e-01, 3.04938797e-04, 1.36978729e-14]), array([9.99894675e-01, 1.05324816e-04, 1.70228946e-17]), array([1.68106097e-04, 9.88428671e-01, 1.14032228e-02]), array([1.71204232e-09, 6.96660699e-04, 9.99303338e-01]), array([9.96721595e-01, 3.27840486e-03, 6.44846199e-14]), array([9.99245194e-01, 7.54806478e-04, 2.88574087e-14]), array([1.07396737e-11, 1.36018872e-05, 9.99986398e-01]), array([9.98777986e-01, 1.22201367e-03, 4.33477628e-16]), array([8.16550291e-12, 3.21552669e-05, 9.99967845e-01]), array([9.97113671e-01, 2.88632902e-03, 4.22107686e-14]), array([2.65346461e-10, 5.90779904e-05, 9.99940922e-01]), array([9.98414200e-12, 3.80575255e-03, 9.96194247e-01]), array([2.78028049e-04, 9.98691649e-01, 1.03032337e-03]), array([2.67099801e-05, 9.99906404e-01, 6.68865152e-05]), array([9.99007468e-01, 9.92531547e-04, 1.03557075e-14]), array([1.73318378e-09, 7.21558717e-05, 9.99927842e-01]), array([8.89840256e-01, 1.10159744e-01, 6.29114571e-11]), array([7.17274749e-06, 9.03137730e-01, 9.68550975e-02]), array([1.35976368e-07, 7.27175235e-02, 9.27282341e-01]), array([7.39453828e-03, 9.92532329e-01, 7.31329466e-05]), array([3.89988013e-04, 9.99555007e-01, 5.50051678e-05]), array([5.54821035e-05, 9.98484491e-01, 1.46002643e-03]), array([4.10169158e-07, 5.28187290e-02, 9.47180861e-01]), array([9.99906950e-01, 9.30496071e-05, 3.18970401e-18])]\n",
                        "[[0, 0, 1], [0, 1, 0], [0, 1, 0], [0, 0, 1], [0, 1, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [0, 1, 0], [0, 0, 1], [1, 0, 0], [1, 0, 0], [0, 0, 1], [1, 0, 0], [0, 0, 1], [1, 0, 0], [0, 0, 1], [0, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 0], [0, 0, 1], [1, 0, 0], [0, 1, 0], [0, 0, 1], [0, 1, 0], [0, 1, 0], [0, 1, 0], [0, 0, 1], [1, 0, 0]]\n",
                        "Accuracy:  0.16666666666666666\n"
                    ]
                }
            ],
            "source": [
                "new_model = MLPClassifier.load_model(\"model-iris.json\")\n",
                "new_model.printModel()\n",
                "\n",
                "print(\"Prediction:\", new_model.predict(X_test))\n",
                "print(y_test)\n",
                "  \n",
                "# Evaluate model\n",
                "score = model.calc_score(X_test, y_test) \n",
                "\n",
                "print(\"Accuracy: \", score) "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Pengujian menggunakan library scikit-learn"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Dikarenakan inisialisasi model pada library scikit-learn tidak dapat didefinisikan initial weights-nya, maka parameter initial_weights tidak digunakan."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Prediction: [[0 0 1]\n",
                        " [0 1 0]\n",
                        " [0 1 0]\n",
                        " [0 0 1]\n",
                        " [0 1 0]\n",
                        " [1 0 0]\n",
                        " [1 0 0]\n",
                        " [1 0 0]\n",
                        " [0 1 0]\n",
                        " [0 0 1]\n",
                        " [1 0 0]\n",
                        " [1 0 0]\n",
                        " [0 0 1]\n",
                        " [1 0 0]\n",
                        " [0 0 1]\n",
                        " [1 0 0]\n",
                        " [0 0 1]\n",
                        " [0 0 1]\n",
                        " [0 1 0]\n",
                        " [0 1 0]\n",
                        " [1 0 0]\n",
                        " [0 0 1]\n",
                        " [1 0 0]\n",
                        " [0 1 0]\n",
                        " [0 0 1]\n",
                        " [0 1 0]\n",
                        " [0 1 0]\n",
                        " [0 1 0]\n",
                        " [0 0 1]\n",
                        " [1 0 0]]\n",
                        "Accuracy:  1.0\n"
                    ]
                }
            ],
            "source": [
                "from sklearn.neural_network import MLPClassifier\n",
                "# Define the model with mini-batch gradient descent \n",
                "model = MLPClassifier(hidden_layer_sizes=(3),learning_rate='constant', learning_rate_init=0.1, alpha=0.0001, solver='sgd', batch_size=50, max_iter=1000, activation='relu') \n",
                "  \n",
                "# Train model\n",
                "model.fit(X_train, y_train) \n",
                "print(\"Prediction:\", model.predict(X_test))\n",
                "  \n",
                "# Evaluate model\n",
                "score = model.score(X_test, y_test) \n",
                "print(\"Accuracy: \", score) "
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.1"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
