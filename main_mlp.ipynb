{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Utility Function"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 36,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "\n",
                "\n",
                "def linear(x):\n",
                "    return x\n",
                "\n",
                "\n",
                "def relu(x):\n",
                "    return np.maximum(x, 0)\n",
                "\n",
                "\n",
                "def sigmoid(x):\n",
                "    return 1.0 / (1.0 + np.exp(-x))\n",
                "\n",
                "\n",
                "def softmax(x):\n",
                "    e_x = np.exp(x - np.max(x))\n",
                "    return e_x / e_x.sum(axis=0)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## MLPClassifier Implementation"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Parameter yang ada pada kelas MLPClassifier yaitu: **struktur jaringan (jumlah layer, jumlah neuron setiap layer, fungsi aktivasi setiap layer), initial weights tiap neuron, learning_rate, error_threshold, max_iter, batch_size**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 37,
            "metadata": {},
            "outputs": [],
            "source": [
                "import math\n",
                "import numpy as np\n",
                "import os\n",
                "import json\n",
                "from utils import sigmoid, relu, softmax, linear\n",
                "\n",
                "\n",
                "class FFNNLayer:\n",
                "    def __init__(self, number_of_neurons: int, activation_function: str):\n",
                "        \"\"\"\n",
                "        :param number_of_neurons:\n",
                "        :param activation_function:\n",
                "        \"\"\"\n",
                "        self.number_of_neurons = number_of_neurons\n",
                "        self.activation_function = activation_function\n",
                "\n",
                "\n",
                "class MLPClassifier:\n",
                "    def __init__(self, layers: list, weights, learning_rate=None, error_threshold=None, max_iter=None, batch_size=None,  stopped_by=None, expected_weights = None):\n",
                "        \"\"\"\n",
                "        :param layers: list of FFNNLayer to specify the activation function and num of neurons for each layers\n",
                "        :param learning_rate: the learning rate\n",
                "        :param error_threshold: the error threshold\n",
                "        :param max_iter: max iter to stop iteration\n",
                "        :param batch_size: the size of batch for each mini batch\n",
                "        \"\"\"\n",
                "        self.num_of_layers = len(layers)\n",
                "        self.layers = layers\n",
                "        self.learning_rate = learning_rate\n",
                "        self.error_threshold = error_threshold\n",
                "        self.error_sum = 1\n",
                "        self.max_iter = max_iter\n",
                "        self.batch_size = batch_size\n",
                "        self.X_train = []\n",
                "        self.y_train = []\n",
                "        self.neuron_values = []\n",
                "        self.weights = [weight[1:] for weight in weights]\n",
                "        self.bias_weights = [weight[0] for weight in weights]\n",
                "        self.prediction = []\n",
                "        self.num_of_features = 0\n",
                "        self.num_of_batches = 0\n",
                "        self.d_weights = None\n",
                "        self.d_bias_weights = None\n",
                "        self.expected_stopped_by = stopped_by\n",
                "        self.expected_weights = expected_weights\n",
                "        self.expected_output = None\n",
                "        self.stopped_by = None\n",
                "        self.current_inputs = None\n",
                "\n",
                "    def fit(self, X_train, y_train):\n",
                "        self.X_train = X_train\n",
                "        self.y_train = y_train\n",
                "        self.num_of_features = len(self.X_train)\n",
                "        self.num_of_batches = math.ceil(len(self.X_train) / self.batch_size)\n",
                "\n",
                "        # the first neuron is the X inputs themselves\n",
                "        self.neuron_values = [[None for _ in range(layer.number_of_neurons)] for layer in self.layers]\n",
                "        num_iter = 0\n",
                "        while num_iter < self.max_iter:\n",
                "            num_of_batches = math.ceil(len(self.X_train) / self.batch_size)\n",
                "            err = 0\n",
                "            for i in range(num_of_batches):\n",
                "                self.__forward(i)\n",
                "                self.__backward(i)\n",
                "                err += self.__calculate_error(i)\n",
                "\n",
                "            # Update the average error for this iteration\n",
                "            self.error_sum = err / num_of_batches\n",
                "\n",
                "            # Check if the error is below the threshold\n",
                "            if self.error_sum <= self.error_threshold:\n",
                "                break\n",
                "\n",
                "            num_iter += 1\n",
                "\n",
                "        self.stopped_by = \"max_iteration\" if num_iter == self.max_iter else \"error_threshold\"\n",
                "\n",
                "        if self.expected_weights:\n",
                "            self.__print_final_weights()\n",
                "\n",
                "    def predict(self, X_test):\n",
                "        \"\"\"Perform forward pass to make predictions on input X_test\n",
                "\n",
                "        Args:\n",
                "            X_test: Input data for prediction (list)\n",
                "\n",
                "        Returns:\n",
                "            Predicted outputs for each sample in X_test\n",
                "        \"\"\"\n",
                "        current_inputs = np.array(X_test)\n",
                "        for i in range(self.num_of_layers):\n",
                "            net = [np.matmul(x, self.weights[i]) + self.bias_weights[i] for x in current_inputs]\n",
                "            act_func = self.layers[i].activation_function\n",
                "            if act_func == 'linear':\n",
                "                res = [linear(x) for x in net]\n",
                "            elif act_func == 'relu':\n",
                "                res = [relu(n) for n in net]\n",
                "            elif act_func == 'sigmoid':\n",
                "                res = [sigmoid(n) for n in net]\n",
                "            elif act_func == \"softmax\":\n",
                "                res = [softmax(n) for n in net]\n",
                "            current_inputs = res\n",
                "        return res\n",
                "\n",
                "    def calculate_sse(self):\n",
                "        sse = 0\n",
                "        for layer in range(len(self.expected_weights)):\n",
                "            for neuron in range(len(self.expected_weights[layer])):\n",
                "                expected = np.array(self.expected_weights[layer][neuron])\n",
                "                result = self.bias_weights[layer] if neuron == 0 else self.weights[layer][neuron-1]\n",
                "                squared_error = (expected - result) ** 2\n",
                "                sse += np.sum(squared_error)\n",
                "        return sse\n",
                "\n",
                "    def __forward(self, batch):\n",
                "        start_idx = self.batch_size * batch\n",
                "        self.expected_output = self.y_train[start_idx:start_idx + self.__get_curr_batch_size(batch)]\n",
                "        self.current_inputs = self.X_train[start_idx:start_idx + self.__get_curr_batch_size(batch)]\n",
                "        res = self.current_inputs\n",
                "        for i in range(self.num_of_layers):\n",
                "            net = [np.matmul(x, self.weights[i]) + self.bias_weights[i] for x in res]\n",
                "            act_func = self.layers[i].activation_function\n",
                "            if act_func == 'linear':\n",
                "                res = [linear(x) for x in net]\n",
                "            if act_func == 'relu':\n",
                "                res = [relu(n) for n in net]\n",
                "            if act_func == 'sigmoid':\n",
                "                res = [sigmoid(n) for n in net]\n",
                "            if act_func == \"softmax\":\n",
                "                res = [softmax(n) for n in net]\n",
                "            self.neuron_values[i] = res\n",
                "        # print(\"pred\", self.neuron_values[-1])    \n",
                "        self.prediction = list(self.neuron_values[-1])\n",
                "\n",
                "    def __backward(self, batch_idx):\n",
                "        \"\"\"\n",
                "        do backward propagation for each batch\n",
                "        :param batch_idx: the current batch that is processed\n",
                "        \"\"\"\n",
                "        self.__init_d_weights()\n",
                "        # get the current batch size\n",
                "        batch_size = self.__get_curr_batch_size(batch_idx)\n",
                "\n",
                "        # for each X in the batch\n",
                "        for i in range(batch_size):\n",
                "            d_k = np.zeros(0)\n",
                "            for j in range(self.num_of_layers - 1, -1, -1):\n",
                "                if j == self.num_of_layers - 1:       \n",
                "                    delta = self.__calc_output_layer_delta(i)\n",
                "                else:\n",
                "                    delta = self.__calc_hidden_layer_delta(i, j, d_k)\n",
                "                x = self.current_inputs[i] if j == 0 else self.neuron_values[j - 1][i]\n",
                "                self.d_weights[j] += np.array([[d * n for d in delta] for n in x])\n",
                "                self.d_bias_weights[j] += np.array(delta)\n",
                "                d_k = delta.reshape(delta.shape[0], 1)\n",
                "        \n",
                "        self.weights = [np.array(self.weights[k]) + np.array(self.d_weights[k]) * self.learning_rate for k in\n",
                "                        range(len(self.weights))]\n",
                "        self.bias_weights = [np.array(self.bias_weights[k]) + np.array(self.d_bias_weights[k]) * self.learning_rate for\n",
                "                             k in range(len(self.bias_weights))]\n",
                "\n",
                "    def __calculate_error(self, batch_idx):\n",
                "        \"\"\"\n",
                "        Calculate the error for the current batch\n",
                "        :param batch_idx: the current batch that is processed\n",
                "        \"\"\"\n",
                "        start_idx = self.batch_size * batch_idx\n",
                "        end_idx = start_idx + self.__get_curr_batch_size(batch_idx)\n",
                "        y_true = np.array(self.y_train[start_idx:end_idx])\n",
                "        y_pred = np.array(self.prediction)\n",
                "\n",
                "        # Get the activation function of the output layer\n",
                "        act_func = self.layers[-1].activation_function\n",
                "\n",
                "        # Calculate the error based on the activation function\n",
                "        if act_func in ['relu', 'sigmoid', 'linear']:\n",
                "            return 0.5 * np.sum((y_true - y_pred) ** 2)\n",
                "        elif act_func == 'softmax':\n",
                "            return -np.sum(y_true * np.log(y_pred))\n",
                "        else:\n",
                "            raise ValueError(f\"Unsupported activation function: {act_func}\")\n",
                "\n",
                "    def __update_weights(self):\n",
                "        self.weights = [np.array(self.weights[k]) + np.array(self.d_weights[k]) * self.learning_rate for k in\n",
                "                        range(len(self.weights))]\n",
                "        self.bias_weights = [np.array(self.bias_weights[k]) + np.array(self.d_bias_weights[k]) * self.learning_rate for\n",
                "                             k in range(len(self.bias_weights))]\n",
                "\n",
                "    def __init_d_weights(self):\n",
                "        self.d_weights = [np.array([np.zeros(len(neuron_weight)) for neuron_weight in layer_weight])\n",
                "                          for layer_weight in self.weights]\n",
                "        self.d_bias_weights = [np.zeros(layer.number_of_neurons) for layer in self.layers]\n",
                "\n",
                "    def __calc_output_diff(self, x_idx: int) -> np.ndarray:\n",
                "        \"\"\"\n",
                "        :param x_idx:  the index of the current input on the X_train\n",
                "        \"\"\"\n",
                "        y_train = self.expected_output[x_idx]  # get the expected output of the x\n",
                "        output = self.prediction[x_idx]  # get the prediction\n",
                "        return np.array([y - p for y, p in zip(y_train, output)])\n",
                "\n",
                "    def __calc_act_function_derivative(self, act_func: str, y: list, target=None) -> np.ndarray:\n",
                "        \"\"\"\n",
                "        :param y:  y is the output in a layer\n",
                "\n",
                "        :return : a 1D array which is the sigmoid gradient of the neurons in a layer\n",
                "        \"\"\"\n",
                "        if act_func == 'sigmoid':\n",
                "            return np.array([x * (1-x) for x in y])\n",
                "\n",
                "        elif act_func == 'relu':\n",
                "            return np.array([1 if x > 0 else 0 for x in y])\n",
                "\n",
                "        elif act_func == 'linear':\n",
                "            return np.array([1 for _ in y])\n",
                "\n",
                "        elif act_func == 'softmax':\n",
                "            if target is None:\n",
                "                raise ValueError(\"Target is required for softmax gradient\")\n",
                "            return np.array([-1 * (1-y[i]) if target == i else y[i] for i in range(len(y))])\n",
                "\n",
                "        else:\n",
                "            raise ValueError(f\"Unknown activation function: {act_func}\")\n",
                "\n",
                "\n",
                "    def __calc_output_layer_delta(self, x_idx: int) -> np.ndarray:\n",
                "        \"\"\"\n",
                "        :param x_idx:  the index of the current input on the X_train\n",
                "        \"\"\"\n",
                "        # get the activation function for the last layer (output layer)\n",
                "        act_func = self.layers[-1].activation_function  # get the activation function\n",
                "    \n",
                "        if act_func == 'softmax':\n",
                "            return self.__calc_output_diff(x_idx)\n",
                "        return self.__calc_act_function_derivative(act_func, self.prediction[x_idx]) * self.__calc_output_diff(x_idx)\n",
                "\n",
                "    def __calc_hidden_layer_delta(self, batch_idx, layer_idx: int, output_error_term: np.ndarray) -> np.ndarray:\n",
                "        \"\"\"\n",
                "        :param output_error_term: a 1D array of the error term of each weight calculated from the layer after\n",
                "        :param layer_idx: the index of the current layer\n",
                "        :param batch_idx: the index of the current batch\n",
                "\n",
                "        hidden layer gradient = net gradient of the neuron values of current layer * the sum of weight * output error term\n",
                "        \"\"\"\n",
                "        act_func = self.layers[layer_idx].activation_function\n",
                "        activation_func_derivative = self.__calc_act_function_derivative(act_func,\n",
                "                                                                         self.neuron_values[layer_idx][batch_idx])\n",
                "\n",
                "        sum_d_net = [x[0] for x in np.matmul(self.weights[layer_idx + 1], output_error_term)]\n",
                "        return np.array(activation_func_derivative\n",
                "                        * sum_d_net)\n",
                "\n",
                "    def __get_curr_batch_size(self, batch_idx):\n",
                "        mod_res = len(self.X_train) % self.batch_size\n",
                "        if batch_idx == self.num_of_batches - 1 and mod_res != 0:\n",
                "            return mod_res\n",
                "        return self.batch_size\n",
                "\n",
                "    def __print_final_weights(self):\n",
                "        print(\"========= EXPECTED =========\")\n",
                "        for weight in self.expected_weights:\n",
                "            print(\"[\")\n",
                "            for neuron_weight in weight:\n",
                "                print(\"  \", neuron_weight)\n",
                "            print(\"], \")\n",
                "        print(\"STOPPED BY: \", self.expected_stopped_by)\n",
                "\n",
                "        print(\"========== ACTUAL ==========\")\n",
                "\n",
                "        for i in range(len(self.weights)):\n",
                "            print(\"[\")\n",
                "            print(\"  \", self.bias_weights[i])\n",
                "            for neuron_weight in self.weights[i]:\n",
                "                print(\"  \", neuron_weight)\n",
                "            print(\"], \")\n",
                "        print(\"STOPPED BY: \", self.stopped_by)\n",
                "    \n",
                "    def calc_score(self, y_true, predictions):\n",
                "        \"\"\"\n",
                "        Calculate the accuracy of predictions.\n",
                "\n",
                "        :param y_true: True labels.\n",
                "        :param predictions: Predictions from the model, as probabilities.\n",
                "        \n",
                "        :return: Accuracy as a float.\n",
                "        \"\"\"\n",
                "        y_pred_indices = np.argmax(predictions, axis=1)\n",
                "        y_true_indices = np.argmax(y_true, axis=1)\n",
                "        \n",
                "        accuracy = np.mean(y_pred_indices == y_true_indices)\n",
                "        return accuracy\n",
                "    \n",
                "    def save_model(self, file_name, directory=\"model\"):\n",
                "            \"\"\"\n",
                "            Saves the model weights and configuration to model directory.\n",
                "            \"\"\"\n",
                "            if not os.path.exists(directory):\n",
                "                os.makedirs(directory)\n",
                "            \n",
                "            model_data = {\n",
                "            \"final_weights\": [],\n",
                "            \"config\": {\n",
                "                \"layers\": [{\"number_of_neurons\": layer.number_of_neurons,\n",
                "                            \"activation_function\": layer.activation_function} for layer in self.layers],\n",
                "                }\n",
                "            }\n",
                "\n",
                "            for weights, bias in zip(self.weights, self.bias_weights):\n",
                "                bias_rounded = np.round(bias, 6)\n",
                "                weights_rounded = np.round(weights,6)\n",
                "                bias_reshaped = np.reshape(bias_rounded, (1, len(bias_rounded)))\n",
                "                integrated_layer_weights = np.vstack([bias_reshaped, weights_rounded])\n",
                "                model_data[\"final_weights\"].append(integrated_layer_weights.tolist())\n",
                "\n",
                "            new_file_name = \"model-\" + os.path.basename(file_name)\n",
                "            # Save to JSON file\n",
                "            with open(os.path.join(directory, new_file_name), \"w\") as json_file:\n",
                "                json.dump(model_data, json_file)\n",
                "            \n",
                "            print(\"Model saved successfully to JSON.\")\n",
                "\n",
                "    @classmethod\n",
                "    def load_model(cls, file_name, directory=\"model\"):\n",
                "        \"\"\"\n",
                "        Loads the model weights and configuration from model directory.\n",
                "        \"\"\"\n",
                "        # Load configuration\n",
                "        with open(os.path.join(directory, file_name), \"r\") as json_file:\n",
                "            model_data = json.load(json_file)\n",
                "        \n",
                "        layers = [FFNNLayer\n",
                "                  (layer_conf[\"number_of_neurons\"], layer_conf[\"activation_function\"])\n",
                "                  for layer_conf in model_data[\"config\"][\"layers\"]\n",
                "                ]\n",
                "        \n",
                "        #  Create new instance\n",
                "        classifier = cls(\n",
                "            layers=layers,\n",
                "            weights=[],  \n",
                "        )\n",
                "\n",
                "        classifier.weights = []\n",
                "        classifier.bias_weights = []\n",
                "        for integrated_weights in model_data[\"final_weights\"]:\n",
                "            np_weights = np.array(integrated_weights)\n",
                "            classifier.bias_weights.append(np_weights[0, :])\n",
                "            classifier.weights.append(np_weights[1:, :])  \n",
                "        return classifier\n",
                "    \n",
                "    def printModel(self):\n",
                "        for i in range(len(self.weights)):\n",
                "            print(\"[\")\n",
                "            print(\"  \", self.bias_weights[i])\n",
                "            for neuron_weight in self.weights[i]:\n",
                "                print(\"  \", neuron_weight)\n",
                "            print(\"], \")\n",
                "    "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Main Program"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Dijalankan untuk melakukan pengujian berdasarkan test case yang diberikan. Test case diuji dengan menuliskan path dari file test case pada input."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 38,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "========= EXPECTED =========\n",
                        "[\n",
                        "   [0.08592, 0.32276]\n",
                        "   [-0.33872, 0.46172]\n",
                        "   [0.449984, 0.440072]\n",
                        "], \n",
                        "[\n",
                        "   [0.2748, 0.188]\n",
                        "   [0.435904, -0.53168]\n",
                        "   [0.68504, 0.7824]\n",
                        "], \n",
                        "STOPPED BY:  max_iteration\n",
                        "========== ACTUAL ==========\n",
                        "[\n",
                        "   [0.08592 0.32276]\n",
                        "   [-0.33872  0.46172]\n",
                        "   [0.449984 0.440072]\n",
                        "], \n",
                        "[\n",
                        "   [0.2748 0.188 ]\n",
                        "   [ 0.435904 -0.53168 ]\n",
                        "   [0.68504 0.7824 ]\n",
                        "], \n",
                        "STOPPED BY:  max_iteration\n",
                        "Sum Squared Error: 0.0000\n",
                        "Sum Squared Error(SSE) of prediction is lower than Maximum SSE\n",
                        "Model saved successfully to JSON.\n"
                    ]
                }
            ],
            "source": [
                "import json\n",
                "file_path = input(\"Enter json file path: \")\n",
                "f = open(file_path)\n",
                "data = json.load(f)\n",
                "\n",
                "try:\n",
                "    data_layers = data[\"case\"][\"model\"][\"layers\"]\n",
                "    layers = []\n",
                "    for layer in data_layers:\n",
                "        activation_func = layer[\"activation_function\"]\n",
                "        if activation_func not in [\"linear\", \"relu\", \"sigmoid\", \"softmax\"]:\n",
                "            raise Exception(\"Activation function \" + activation_func + \" not available\")\n",
                "        layers.append(FFNNLayer(layer[\"number_of_neurons\"], activation_func))\n",
                "\n",
                "    weights = data[\"case\"][\"initial_weights\"]\n",
                "    input_size = data[\"case\"][\"model\"][\"input_size\"]\n",
                "    X_train = data[\"case\"][\"input\"]\n",
                "    y_train = data[\"case\"][\"target\"]\n",
                "    learning_rate = data[\"case\"][\"learning_parameters\"][\"learning_rate\"]\n",
                "    batch_size = data[\"case\"][\"learning_parameters\"][\"batch_size\"]\n",
                "    max_iteration = data[\"case\"][\"learning_parameters\"][\"max_iteration\"]\n",
                "    error_threshold = data[\"case\"][\"learning_parameters\"][\"error_threshold\"]\n",
                "\n",
                "    expected_weights = data[\"expect\"][\"final_weights\"]\n",
                "    expected_stopped_by = data[\"expect\"][\"stopped_by\"]\n",
                "\n",
                "    model = MLPClassifier(layers, weights, learning_rate, error_threshold, max_iteration, batch_size, expected_stopped_by, expected_weights)\n",
                "\n",
                "    model.fit(X_train, y_train)\n",
                "\n",
                "    sse = model.calculate_sse()\n",
                "    print(f\"Sum Squared Error: {sse:.4f}\")\n",
                "    if sse < 1e-7:\n",
                "        print(\"Sum Squared Error(SSE) of prediction is lower than Maximum SSE\")\n",
                "    else:\n",
                "        print(\"Sum Squared Error(SSE) of prediction surpass the Maximum SSE\")\n",
                "    model.save_model(file_path)\n",
                "except KeyError as ke:\n",
                "    print('Key', ke, \"not found in json data. Please check your json data format\")\n",
                "except Exception as error:\n",
                "    print(\"An exception occurred: \", error)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 39,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[\n",
                        "   [0.08592 0.32276]\n",
                        "   [-0.33872  0.46172]\n",
                        "   [0.449984 0.440072]\n",
                        "], \n",
                        "[\n",
                        "   [0.2748 0.188 ]\n",
                        "   [ 0.435904 -0.53168 ]\n",
                        "   [0.68504 0.7824 ]\n",
                        "], \n"
                    ]
                }
            ],
            "source": [
                "model = MLPClassifier.load_model(\"model-mlp.json\")\n",
                "model.printModel()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Pengujian pada Dataset Iris"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Akan dilakukan pengujian pada dataset iris dengan parameter sebagai berikut:\n",
                "* Struktur jaringan: 2 hidden layer dengan masing-masing 3 neuron dan fungsi aktivasi ReLU\n",
                "* Initial weights: akan diinitialize secara random dengan nilai dalam interval -0.5 - 0.5\n",
                "* learning_rate: 0.1\n",
                "* error_threshold: 0.0001\n",
                "* max_iter: 1000\n",
                "* batch_size: 50"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Preprocessing data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 40,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[[0, 1, 0], [1, 0, 0], [0, 0, 1], [0, 1, 0], [1, 0, 0], [0, 0, 1], [0, 1, 0], [1, 0, 0], [0, 1, 0], [1, 0, 0], [0, 0, 1], [0, 1, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [0, 0, 1], [0, 1, 0], [0, 0, 1], [0, 1, 0], [0, 0, 1], [0, 1, 0], [1, 0, 0], [1, 0, 0], [0, 1, 0], [0, 0, 1], [0, 1, 0], [0, 0, 1], [0, 1, 0], [0, 1, 0], [0, 1, 0], [0, 0, 1], [1, 0, 0], [0, 1, 0], [1, 0, 0], [0, 0, 1], [1, 0, 0], [1, 0, 0], [0, 0, 1], [0, 1, 0], [0, 0, 1], [0, 0, 1], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [0, 1, 0], [0, 0, 1], [0, 1, 0], [0, 1, 0], [0, 1, 0], [0, 0, 1], [1, 0, 0], [0, 0, 1], [0, 0, 1], [0, 1, 0], [0, 1, 0], [0, 1, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [0, 0, 1], [1, 0, 0], [0, 0, 1], [1, 0, 0], [0, 1, 0], [0, 1, 0], [0, 0, 1], [1, 0, 0], [0, 0, 1], [1, 0, 0], [0, 0, 1], [0, 0, 1], [1, 0, 0], [0, 1, 0], [0, 1, 0], [1, 0, 0], [0, 1, 0], [1, 0, 0], [0, 0, 1], [0, 1, 0], [1, 0, 0], [1, 0, 0], [0, 0, 1], [0, 0, 1], [0, 1, 0], [0, 1, 0], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [1, 0, 0], [0, 1, 0], [1, 0, 0], [1, 0, 0], [0, 0, 1], [0, 0, 1], [0, 1, 0], [1, 0, 0], [0, 0, 1], [0, 1, 0], [0, 0, 1], [0, 1, 0], [0, 0, 1], [0, 0, 1], [0, 1, 0], [1, 0, 0], [0, 0, 1], [1, 0, 0], [0, 1, 0], [0, 0, 1], [1, 0, 0], [0, 0, 1], [1, 0, 0], [1, 0, 0], [0, 1, 0], [0, 0, 1], [0, 1, 0], [0, 1, 0], [0, 1, 0]]\n"
                    ]
                }
            ],
            "source": [
                "import numpy as np\n",
                "import pandas as pd\n",
                "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
                "from sklearn.model_selection import train_test_split\n",
                "\n",
                "# Load the data\n",
                "data = pd.read_csv(\"test_cases_mlp/iris.csv\")\n",
                "\n",
                "# Split the data\n",
                "X = data.drop(columns=[\"Species\"])\n",
                "y = data[\"Species\"]\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n",
                "\n",
                "# Standardize the data\n",
                "scaler = StandardScaler()\n",
                "X_train = scaler.fit_transform(X_train)\n",
                "X_test = scaler.transform(X_test)\n",
                "\n",
                "# Encode the data\n",
                "encoder = LabelEncoder()\n",
                "y_train_encoded = encoder.fit_transform(y_train)\n",
                "y_test_encoded = encoder.transform(y_test)\n",
                "\n",
                "def one_hot_encode(labels, num_classes):\n",
                "    one_hot = np.zeros((len(labels), num_classes), dtype=int)\n",
                "    one_hot[np.arange(len(labels)), labels] = 1\n",
                "    return one_hot.tolist()\n",
                "\n",
                "# One-hot encode the labels\n",
                "y_train = one_hot_encode(y_train_encoded, 3)\n",
                "y_test = one_hot_encode(y_test_encoded, 3)\n",
                "\n",
                "print(y_train)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Pengujian pada kelas implementasi MLPClassifier"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 41,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Model saved successfully to JSON.\n",
                        "[array([2.00115172e-11, 6.11338371e-06, 9.99993887e-01]), array([2.24958114e-04, 9.99329477e-01, 4.45565250e-04]), array([0.00886994, 0.98822735, 0.00290271]), array([1.20114969e-06, 9.95561578e-01, 4.43722129e-03]), array([1.63348087e-11, 1.78961586e-05, 9.99982104e-01]), array([9.99916142e-01, 8.38580688e-05, 9.81804010e-17]), array([9.99651982e-01, 3.48018437e-04, 3.76961723e-16]), array([6.89543205e-09, 2.23861340e-03, 9.97761380e-01]), array([9.97867172e-01, 2.13282811e-03, 5.52496180e-13]), array([9.99596249e-01, 4.03751265e-04, 1.58643742e-16]), array([2.59781765e-04, 9.88605197e-01, 1.11350211e-02]), array([7.10134583e-06, 8.74802276e-01, 1.25190623e-01]), array([9.96348510e-01, 3.65148977e-03, 8.96989638e-14]), array([5.93609256e-10, 2.49878456e-03, 9.97501215e-01]), array([3.18819197e-02, 9.68111455e-01, 6.62515878e-06]), array([9.99651826e-01, 3.48174460e-04, 4.41219243e-17]), array([1.94786058e-12, 9.97071029e-06, 9.99990029e-01]), array([9.99448980e-01, 5.51019538e-04, 1.71261563e-15]), array([2.61951131e-08, 9.52867825e-04, 9.99047106e-01]), array([2.37159355e-13, 2.55968199e-06, 9.99997440e-01]), array([2.06831635e-10, 1.17344640e-02, 9.88265536e-01]), array([9.99748083e-01, 2.51917461e-04, 3.92149842e-14]), array([9.99217908e-01, 7.82091933e-04, 2.85071648e-15]), array([0.00128175, 0.96501633, 0.03370192]), array([6.54261982e-04, 9.36379458e-01, 6.29662801e-02]), array([9.99258382e-01, 7.41617868e-04, 1.13124730e-13]), array([1.23146137e-05, 9.73383533e-01, 2.66041522e-02]), array([6.39827480e-12, 3.66360458e-05, 9.99963364e-01]), array([3.73010872e-05, 9.99687165e-01, 2.75534125e-04]), array([1.72543027e-12, 2.58198290e-03, 9.97418017e-01])]\n"
                    ]
                }
            ],
            "source": [
                "import random\n",
                "\n",
                "layers = [\n",
                "    FFNNLayer(3, 'softmax')\n",
                "]\n",
                "initial_weights = [[[random.uniform(-0.5, 0.5) for _ in range(layer.number_of_neurons)] for _ in range (6)] for layer in layers]\n",
                "implementation_model = MLPClassifier(layers=layers,  weights=initial_weights, learning_rate=0.1, error_threshold=0.0001, max_iter=100, batch_size=50, stopped_by=\"error_threshold\")\n",
                "implementation_model.fit(X_train, y_train)\n",
                "implementation_model.save_model(\"iris.json\")\n",
                "print(implementation_model.predict(X_test))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 42,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[\n",
                        "   [-0.60063   4.601566 -3.960843]\n",
                        "   [-2.744752 -2.326934  4.900957]\n",
                        "   [-2.234351  1.116221  0.654724]\n",
                        "   [ 1.938036 -0.48131  -1.056049]\n",
                        "   [-3.074626  0.621315  3.045982]\n",
                        "   [-2.831188 -0.94921   4.264801]\n",
                        "], \n",
                        "Prediction: [array([2.00114975e-11, 6.11337929e-06, 9.99993887e-01]), array([2.24958178e-04, 9.99329477e-01, 4.45565126e-04]), array([0.00886994, 0.98822735, 0.0029027 ]), array([1.20114953e-06, 9.95561583e-01, 4.43721562e-03]), array([1.63348045e-11, 1.78961638e-05, 9.99982104e-01]), array([9.99916142e-01, 8.38579017e-05, 9.81804000e-17]), array([9.99651982e-01, 3.48017776e-04, 3.76961576e-16]), array([6.89543332e-09, 2.23861457e-03, 9.97761379e-01]), array([9.97867175e-01, 2.13282501e-03, 5.52495754e-13]), array([9.99596249e-01, 4.03750566e-04, 1.58643598e-16]), array([2.59781771e-04, 9.88605204e-01, 1.11350141e-02]), array([7.10134491e-06, 8.74802329e-01, 1.25190570e-01]), array([9.96348516e-01, 3.65148362e-03, 8.96989183e-14]), array([5.93609078e-10, 2.49878472e-03, 9.97501215e-01]), array([3.18819360e-02, 9.68111439e-01, 6.62515636e-06]), array([9.99651826e-01, 3.48173781e-04, 4.41219108e-17]), array([1.94785999e-12, 9.97071089e-06, 9.99990029e-01]), array([9.99448981e-01, 5.51018584e-04, 1.71261493e-15]), array([2.61951075e-08, 9.52867817e-04, 9.99047106e-01]), array([2.37159210e-13, 2.55968205e-06, 9.99997440e-01]), array([2.06831736e-10, 1.17344790e-02, 9.88265521e-01]), array([9.99748083e-01, 2.51917075e-04, 3.92149647e-14]), array([9.99217909e-01, 7.82090593e-04, 2.85071494e-15]), array([0.00128175, 0.96501631, 0.03370195]), array([6.54262031e-04, 9.36379472e-01, 6.29662657e-02]), array([9.99258383e-01, 7.41616745e-04, 1.13124671e-13]), array([1.23146140e-05, 9.73383537e-01, 2.66041482e-02]), array([6.39827303e-12, 3.66360550e-05, 9.99963364e-01]), array([3.73010977e-05, 9.99687165e-01, 2.75534110e-04]), array([1.72543026e-12, 2.58198507e-03, 9.97418015e-01])]\n",
                        "[[0, 0, 1], [0, 1, 0], [0, 1, 0], [0, 1, 0], [0, 0, 1], [1, 0, 0], [1, 0, 0], [0, 0, 1], [1, 0, 0], [1, 0, 0], [0, 1, 0], [0, 1, 0], [1, 0, 0], [0, 0, 1], [0, 1, 0], [1, 0, 0], [0, 0, 1], [1, 0, 0], [0, 0, 1], [0, 0, 1], [0, 0, 1], [1, 0, 0], [1, 0, 0], [0, 1, 0], [0, 1, 0], [1, 0, 0], [0, 1, 0], [0, 0, 1], [0, 1, 0], [0, 0, 1]]\n",
                        "Accuracy:  1.0\n"
                    ]
                }
            ],
            "source": [
                "new_model = MLPClassifier.load_model(\"model-iris.json\")\n",
                "new_model.printModel()\n",
                "prediction = new_model.predict(X_test)\n",
                "print(\"Prediction:\", prediction)\n",
                "print(y_test)\n",
                "  \n",
                "# Evaluate model\n",
                "score = model.calc_score(y_test, prediction) \n",
                "\n",
                "print(\"Accuracy: \", score) "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Pengujian menggunakan library scikit-learn"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Dikarenakan inisialisasi model pada library scikit-learn tidak dapat didefinisikan initial weights-nya, maka parameter initial_weights tidak digunakan."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 43,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Prediction: [[0 0 1]\n",
                        " [0 1 0]\n",
                        " [0 1 0]\n",
                        " [0 1 0]\n",
                        " [0 0 1]\n",
                        " [1 0 0]\n",
                        " [1 0 0]\n",
                        " [0 0 1]\n",
                        " [1 0 0]\n",
                        " [1 0 0]\n",
                        " [0 1 0]\n",
                        " [0 1 0]\n",
                        " [1 0 0]\n",
                        " [0 0 1]\n",
                        " [0 1 0]\n",
                        " [1 0 0]\n",
                        " [0 0 1]\n",
                        " [1 0 0]\n",
                        " [0 0 1]\n",
                        " [0 0 1]\n",
                        " [0 0 1]\n",
                        " [1 0 0]\n",
                        " [1 0 0]\n",
                        " [0 1 0]\n",
                        " [0 1 0]\n",
                        " [1 0 0]\n",
                        " [0 1 0]\n",
                        " [0 0 1]\n",
                        " [0 1 0]\n",
                        " [0 0 1]]\n",
                        "Accuracy:  1.0\n"
                    ]
                }
            ],
            "source": [
                "from sklearn.neural_network import MLPClassifier\n",
                "# Define the model with mini-batch gradient descent \n",
                "model = MLPClassifier(hidden_layer_sizes=(3),learning_rate='constant', learning_rate_init=0.1, alpha=0.0001, solver='sgd', batch_size=50, max_iter=1000, activation='relu') \n",
                "  \n",
                "# Train model\n",
                "model.fit(X_train, y_train) \n",
                "print(\"Prediction:\", model.predict(X_test))\n",
                "  \n",
                "# Evaluate model\n",
                "score = model.score(X_test, y_test) \n",
                "print(\"Accuracy: \", score) "
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.1"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
